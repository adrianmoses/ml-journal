{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AI and ML for Coders Ch 2\n",
    "\n",
    "I'm very interested in receiving the Tensorflow Dev Certificate\n",
    "\n",
    "It's really an opportunity to move into the ML space more confidently. And build my expertise in the field.\n",
    "\n",
    "However, I'm not sure the best way to prepare for the exam. It may not be that tough, but I'm not sure. After noticing the [Tensorflow Developer Certificate Specialization](http://courser.org) on Coursera, I took a peak at the courses and noticed something familiar.\n",
    "\n",
    "The synopsis of the specialization is identical to the book AI and Machine Learning for Coders. This isn't completely surprising because the instructor of the specialization is also the author of said book.\n",
    "\n",
    "So I'm going to work through each chapter to get the dust off of my TF dev skills. Though, that won't be all. I'll also want to build a few projects from scratch. But we'll get there soon. \n",
    "\n",
    "So here's ch 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Computer Vision\n",
    "\n",
    "The ability to algorithmicly see an image as a type of clothing is very difficult to define with rule-based programming. Instead, let's use machine learning.\n",
    "\n",
    "Using the Fashion MNIST dataset we have 10 types of images based on clothing types. Each image is 28x28 and is in black and white. Meaning each pixel value is between 0 and 255.\n",
    "\n",
    "We can't model a linear relationship between the X (image pixels) and the Y (clothing type)\n",
    "\n",
    "However we can use the output node layer as a represenation of the 10 clothing types. Each image will be loaded into every node and the output will spit out a probability that the image is of the clothing type the output node represents.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!pip install tensorflow-cpu"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow-cpu\n",
      "  Downloading tensorflow_cpu-2.6.0-cp38-cp38-macosx_10_11_x86_64.whl (199.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 199.0 MB 105 kB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu) (3.7.4.3)\n",
      "Collecting keras~=2.6\n",
      "  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu) (0.36.2)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 29.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu) (1.12.1)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.14.0-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 34.0 MB/s \n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.6 MB 28.5 MB/s \n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.40.0-cp38-cp38-macosx_10_10_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 20.9 MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator~=2.6\n",
      "  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.18.0-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 27.9 MB/s \n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu) (1.15.0)\n",
      "Collecting clang~=5.0\n",
      "  Using cached clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow-cpu) (52.0.0.post20210125)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-cpu) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-cpu) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-cpu) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adrianmoses/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-cpu) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=da15ad6b0d6d4b2a3771249b17258a29cd98a0ec320998b59d0271947a6dc249\n",
      "  Stored in directory: /Users/adrianmoses/Library/Caches/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=0e700811fb720cbb45531971531821ac22f2c4752b8e8da9f111d274868e236f\n",
      "  Stored in directory: /Users/adrianmoses/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow-cpu\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.1\n",
      "    Uninstalling numpy-1.20.1:\n",
      "      Successfully uninstalled numpy-1.20.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "Successfully installed absl-py-0.14.0 astunparse-1.6.3 cachetools-4.2.2 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.40.0 h5py-3.1.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.18.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-cpu-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow import keras"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data = tf.keras.datasets.fashion_mnist # dataset\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = data.load_data() # load data into train and test sets\n",
    "\n",
    "training_images = training_images / 255.0 # normalize the images so that they're all between 0 and 1\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  keras.layers.Dense(128, activation=tf.nn.relu), # hidden layer\n",
    "  keras.layers.Dense(10, activation=tf.nn.softmax) # output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', # adam is an evolution of sgd to better find that global optimum (uses momentum)\n",
    "  loss='sparse_categorical_crossentropy', # common loss function for softmax classification\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "26435584/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "4431872/4422102 [==============================] - 0s 0us/step\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 732us/step - loss: 0.4964 - accuracy: 0.8251\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 745us/step - loss: 0.3719 - accuracy: 0.8655\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 740us/step - loss: 0.3349 - accuracy: 0.8771\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 743us/step - loss: 0.3114 - accuracy: 0.8846\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.2940 - accuracy: 0.8915\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff180afcd00>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model.evaluate(test_images, test_labels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 0s 508us/step - loss: 0.3397 - accuracy: 0.8791\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.3397229313850403, 0.8791000247001648]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# explor the prediction results\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0]) # probabilities for each class\n",
    "print(test_labels[0]) # actual correct class"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.3823378e-05 3.3052868e-07 1.6802342e-05 1.0910228e-06 6.6072988e-07\n",
      " 5.4068407e-03 1.5284693e-05 7.9095788e-02 3.6717476e-05 9.1541272e-01]\n",
      "9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# try 50 epochs to get overfitting\n",
    "model.fit(training_images, training_labels, epochs=50)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.2797 - accuracy: 0.8959\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.2682 - accuracy: 0.9002\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.2574 - accuracy: 0.9042\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 1s 746us/step - loss: 0.2477 - accuracy: 0.9087\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 1s 746us/step - loss: 0.2379 - accuracy: 0.9117\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.2321 - accuracy: 0.9139\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.2225 - accuracy: 0.9169\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.2172 - accuracy: 0.9186\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.2100 - accuracy: 0.9210\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.2045 - accuracy: 0.9230\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.1986 - accuracy: 0.9247\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 1s 774us/step - loss: 0.1913 - accuracy: 0.9276\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.1880 - accuracy: 0.9282\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 1s 757us/step - loss: 0.1821 - accuracy: 0.9323\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.1780 - accuracy: 0.9326\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 1s 754us/step - loss: 0.1728 - accuracy: 0.9335\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.1700 - accuracy: 0.9364\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.1655 - accuracy: 0.9370\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.1602 - accuracy: 0.9388\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.1553 - accuracy: 0.9418\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.1539 - accuracy: 0.9417\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.1505 - accuracy: 0.9436\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.1468 - accuracy: 0.9444\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.1447 - accuracy: 0.9444\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.1399 - accuracy: 0.9472\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.1378 - accuracy: 0.9468\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.1340 - accuracy: 0.9502\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.1305 - accuracy: 0.9508\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 1s 757us/step - loss: 0.1293 - accuracy: 0.9516\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.1275 - accuracy: 0.9526\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.1228 - accuracy: 0.9532\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.1208 - accuracy: 0.9543\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 1s 752us/step - loss: 0.1166 - accuracy: 0.9552\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.1175 - accuracy: 0.9551\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.1173 - accuracy: 0.9556\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 1s 757us/step - loss: 0.1130 - accuracy: 0.9572\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.1120 - accuracy: 0.9571\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.1090 - accuracy: 0.9591\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.1082 - accuracy: 0.9598\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 1s 741us/step - loss: 0.1034 - accuracy: 0.9603\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.1031 - accuracy: 0.9622\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 0.1002 - accuracy: 0.9621\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 1s 740us/step - loss: 0.1014 - accuracy: 0.9619\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 1s 743us/step - loss: 0.0974 - accuracy: 0.9627\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.0962 - accuracy: 0.9638\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0959 - accuracy: 0.9635\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 2s 811us/step - loss: 0.0923 - accuracy: 0.9646\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 2s 810us/step - loss: 0.0910 - accuracy: 0.9653\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.0909 - accuracy: 0.9661\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 2s 884us/step - loss: 0.0879 - accuracy: 0.9676\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1a125fa00>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.evaluate(test_images, test_labels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 0s 559us/step - loss: 0.5352 - accuracy: 0.8879\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.5351569056510925, 0.8878999948501587]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After adding 50 epochs, the training accuracy increased, but the evaluation decreased.\n",
    "This is a sign of _overfitting_ because the model is having a harding time generalizing on data it hasn't seen\n",
    "\n",
    "By the way, always recompile the model when retraining. \n",
    "\n",
    "Let's use _callbacks_ to train the same model but stopping it when an accuracy has been reached."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class myCallback(keras.callbacks.Callback):\n",
    "  \n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if logs.get('accuracy') > 0.95:\n",
    "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=50, callbacks=[callbacks])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 2s 756us/step - loss: 0.4989 - accuracy: 0.8232\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.3711 - accuracy: 0.8649\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.3344 - accuracy: 0.8776\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.3114 - accuracy: 0.8853\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.2932 - accuracy: 0.8913\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.2788 - accuracy: 0.8967\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.2646 - accuracy: 0.9012\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.2573 - accuracy: 0.9042\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 1s 752us/step - loss: 0.2458 - accuracy: 0.9086\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.2399 - accuracy: 0.9111\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.2291 - accuracy: 0.9140\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 1s 759us/step - loss: 0.2235 - accuracy: 0.9167\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.2171 - accuracy: 0.9190\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.2120 - accuracy: 0.9210\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.2069 - accuracy: 0.9226\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.1991 - accuracy: 0.9255\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.1936 - accuracy: 0.9273\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.1892 - accuracy: 0.9290\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.1844 - accuracy: 0.9310\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.1793 - accuracy: 0.9328\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.1762 - accuracy: 0.9338\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.1702 - accuracy: 0.9360\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.1670 - accuracy: 0.9373\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 2s 800us/step - loss: 0.1628 - accuracy: 0.9391\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.1600 - accuracy: 0.9400\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.1559 - accuracy: 0.9410\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 1s 757us/step - loss: 0.1526 - accuracy: 0.9418\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.1479 - accuracy: 0.9440\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.1463 - accuracy: 0.9447\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.1409 - accuracy: 0.9468\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.1395 - accuracy: 0.9477\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.1371 - accuracy: 0.9486\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 1s 754us/step - loss: 0.1353 - accuracy: 0.9484\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.1303 - accuracy: 0.9503\n",
      "\n",
      "Reached 95% accuracy so cancelling training!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1a1261730>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Callbacks are cool! \n",
    "\n",
    "Next chapter will use the more efficient approach of convolutions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ddc328ea8478a771d9b93ec38fb34a01d8dc85ddd5c4232f01fa4bf9ab127a9f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}